This folder represents my ongoing attempts to gather together disparate thoughts into a single place. Possibly arrange them into a narrative, or identify if there are multiple narratives and pare them apart.

Everything seems to come down to the rigidity of formal systems. That there are some factors that prove this is the case and many implications for science and society as a result.

# Reasons for the rigidity


# Implications of the rigidity
## Metaphor of context in AI being like management

A mangement structure starts off ad-hoc, in a system where everyone can speak to everyone else and get a feel for their situation, just like a shared lived experience.
As the company grows there will be fewer connections between the people, and so information needs to get passed in a more formalised manner.
This has the advantage of ignoring irrelevant details, but disadvantage of losing the shared lived-experience.
This isn't so bad if the person who is reporting "up the chain" has freedom to report what they want as they can use their own knowledge and experience to decide which details are relevant on an ad-hoc basis.
This is a problem if the upper manager has dictated what the model of communication must be. E.g. report on these metrics, ignore everything else.

A formally defined communication is efficient but necessarily loses information. This is great when it is known beforehand which information is relevant.

So, as a company grows you run the risk of the lower workers feeling like they are inhumanely treated and simply reaching metrics.
One solution to this is to give each area its own autonomy and enforce that some upper management cannot dictate on certain issues without having appropriate experience.
You end up with something like a distributed system of autonomous (as autonomous as anything can be) agents.
This is probably anathema to modern business, but may lead to more sustainable growth.

## Goodharts law

As soon as a metric becomes the goal, it's no longer a good metric. Well "the metric being the goal" is pretty much the definition of unsupervised learning and reinforcement learning.

All AI risks turning a metric into a goal.
This is fine so long as the metric captures the entire context.
Otherwise you will have artificial maximising of an output, not an outcome.
Especially common is to tune an AI to a context in which the AI itself doesn't exist.
> What is a good example of this? 
> Something where the existance of the AI changes behaviour. Like the random skinner box.
> Maybe votes, encouraging popularism?

# Non-formal AI

## Real time dynamic AI
The idea that an AI is possible which is able to maintain a number of real-time dynamics with phases that resonate with other real-time dynamics in the system and in the environment.

## AI without reason
Can we do AI without Reason? I say we have to. Is it the same as doing real-time dynamic ai? Could real time dynamic AI (RTDAI) enable reason, like a human brain 'running' an algorithm?

## The primary sense is 'feel'
The important thing here is that the main aspect of consciousness is a situational awareness which forms the "background" which determines which stimulii are experienced as meaningful sensations. We think that the consious experience as vision but its better understood as a combination of all sense organs as well as personal history and biology.

Vision is not what you think it is. What you are experiencing is 'feel', vision is a component of that but no more important than history and situational knowledge.

When you're looking around you can see that you're in a street or that you're in a room. If you close your eyes that experience is drastically different, for sure, but pay close attention to the "feelings" that remain. Of you are still likely to "feel" that you are in the street or a room. If you were feeling bored or stressed with your eyes open you'll probably still feel bored or stressed with your eyes closed.

It is sometimes said that vision is the primary sense, it seems to be the most important and first way we learn about what's going on. It is also said (I've heard it from a community which was either about deafness or blindness, I forget) hearing is the social sense.

A neuroscientist said that smell is the primary sense. Defining smell as the sense where soluable chemicals contact the cell membrane. Even touch, oressure sensitivity cones later evolutionarily. Maybe metabolism, but even that assmes soluable chemicals.
