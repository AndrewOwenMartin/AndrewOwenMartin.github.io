# AI

# The primary sense is 'feel'

Vision is not what you think it is. What you are experiencing is 'feel', vision is a component of that but no more important than history and situational knowledge.

# context in AI is like management.

A mangement structure starts of ad-hoc, in a system where everyone can speak to everyone else and get a feel for their situation, just like a shared lived experience.
As the company grows there will be fewer connections between the people, and so information needs to get passed in a more fomalised manner.
This has the advantage of ignoring irellevant details, but disadvantage of losing the shared lived-experience.
This isn't so bad if the person who is reporting "up the chain" has freedom to report what they want as they can use their own knowledge and experience to decide which details are relevant on an ad-hoc basis.
This is a problem if the upper manager has dicitated what the model of communication must be. E.g. report on these metrics, ignore everything else.

A formally defined communication is efficient but necessarily loses information. This is great when it is known beforehand which information is relevant.

So, as a company grows you run the risk of the lower workers feeling like they are inhumanely treated and simply reaching metrics.
One solution to this is to give each area its own autonomy and enforce that some upper management cannot dictate on certain issues without having appropriate experience.
You end up with something like a distributed system of autonomous (as autonomous as anything can be) agents.
This is probably anathema to modern business, but may lead to more sustainable growth.

# goodhart's law

# there is no true autonomy

You may draw a line which defines autonomy, or an agent, in a system, but there is no objective way to draw the one true line.
